# 大数据基础复习

## 大数据基本概念

### 数据与信息的关系***

> 数据是一种未经加工的原始资料。数组、文字、符号、图像都是数据、数据是客观对象的表示，而信息则是数据内涵的意义，是数据的内容和解释。综上所述，数据就是指能够客观反应事实的数字和资料。
>
> 信息与数据的关系是：信息与数据是不可分离的，数据是信息的表达，信息是数据的内涵。数据本身并没有意义数据只有对实体行为产生影响时才成为信息。

### 结构化数据××

结构化信息是指信息经过分析后可分解成多个互相关联的组成部分，各组成部分间有明确的层次结构，其使用和维护通过数据库进行管理，并有一定的操作规范。

我们通常接触的，包括生产、业务、交易、客户信息等方面的记录都属于结构化信息。

结构化数据简单来说就是存储在结构化数据库里的数据，可以用二维表结构来逻辑表达实现的数据。
结合到典型场景中更容易理解，比如企业ERP、财务系统；医疗HIS数据库；教育一卡通；政府行政审批；其他核心数据库等。
这些应用需要包括高速存储应用需求、数据备份需求、数据共享需求以及数据容灾需求。

### 大数据的特点＊＊　４Ｖ

业界通常用4个V  ( 即Volume、Variety、Value、Velocity) 来概括大数据的特征。具体来说，大数据具有4个基本特征：
		第一， Volume ( 大量 )，数据体量巨大，从TB级别，跃升到PB级别。

第二，Variety ( 多样 )，数据类别大和类型多样。即数据类型繁多。
第三，Value ( 价值 )，价值真实性高和密度低，即商业价值高，但价值密度低。 
第四，Velocity ( 高速 )，处理速度快，即处理速度快，实时在线。 

### 云平台与云存储×

基础设置服务＼平台服务＼软件服务

### 大数据在公共服务领域的应用

大数据在公共服务中的交通、医疗、教育、预测服务等领域得到广泛应用。
随着第三方服务机构的参与，公众需求被不断挖掘，应用场景逐步丰富。以下为部分公共服务领域大数据应用的案例。

![image-20220503125452563](C:\Users\A\AppData\Roaming\Typora\typora-user-images\image-20220503125452563.png)

![image-20220503125458388](C:\Users\A\AppData\Roaming\Typora\typora-user-images\image-20220503125458388.png)

![image-20220503125503119](C:\Users\A\AppData\Roaming\Typora\typora-user-images\image-20220503125503119.png)

## 大数据采集与预处理

数据采集过程中涉及到数据抽取＼数据的清洗转换＼数据的加载等三个过程。×

### 大数据采集的四种来源

大数据的采集主要有四种来源***：
管理信息系统、Web 信息系统、物理信息系统、科学实验系统。
（1）管理信息系统
是指企业、机关内部的信息系统，如事务处理系统、办公自动化系统，主要用于经营和管理，为特定用户的工作和业务提供支持。
数据的产生既有终端用户的原始输入，也有系统的二次加工处理。系统的组织结构上是专用的，数据通常是结构化的。

2）Web 信息系统
包括互联网上的各种信息系统，如社交网站、社会媒体、搜索引擎等，主要用于构造虚拟的信息空间，为广大用户提供信息服务和社交服务。
系统的组织结构是开放式的，大部分数据是半结构化或无结构的。
数据的产生者主要是在线用户。电子商务、电子政务是在Web 上运行的管理信息系统。

（3）物理信息系统
是指关于各种物理对象和物理过程的信息系统，如实时监控、实时检测，主要用于生产调度、过程控制、现场指挥、环境保护等。
系统的组织结构上是封闭的，数据由各种嵌入式传感设备产生的，可以是关于物理、化学、生物等性质和状态的基本测量值，也可以是关于行为和状态的音频、视频等多媒体数据。

（4） 科学实验系统
实际上也属于物理信息系统，但其实验环境是预先设定的，主要用于研究和学术，数据是有选择的、可控的，有时可能是人工模拟生成的仿真数据。

### 大数据导入＼预处理的过程×××

大数据处理是将业务系统的数据经过抽取、清洗转换之后加载到数据仓库的过程，目的是将企业中的分散、零乱、标准不统一的数据整合到一起，为企业的决策提供分析的依据。 
数据抽取、清洗与转换是大数据处理最重要的一个环节，通常情况下会花掉整个项目的1/3的时间。

这一过程通常分成三部分：数据抽取、数据的清洗转换、数据的加载，在英文中通常缩写为ETL（Extract、Transform、Load）。
数据的抽取是从各个不同的数据源抽取到处理系统中，在抽取的过程中需要挑选不同的抽取方法，尽可能的提高运行效率。
花费时间最长的是清洗、转换的部分，一般情况下这部分工作量是整个过程的2/3。
数据的加载一般在数据清洗完了之后直接写入数据仓库中去。

### 数据清洗×

过滤结果交给业务主管部门，是否过滤掉由业务部门修正后再进行抽取。不符合要求的数据主要是不完整的数据＼错误的数据和重复的数据三大类。

### 数据转换×

不一致数据转换　　数据粒度的转换　　商务规则的计算

### 数据采集技术×××

ETL是Extraction-Transformation-Loading的缩写，中文名称为数据提取、转换和加载。

ETL负责将分布的、异构数据源中的数据如关系数据、平面数据文件等抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础。

它可以批量完成数据抽取、清洗、转换、装载等任务，不但满足了人们对种类繁多的异构数据库进行整合的需求，同时可以通过增量方式进行数据的后期更新。  

### 数据抽取×

是从数据源中抽取数据的过程，主要有以下几种方式：

全量抽取＼增量抽取＼

### 为什么要预处理数据？×××

1）现实世界的数据是肮脏的（不完整，含噪声，不一致）
（2）没有高质量的数据，就没有高质量的挖掘
（3）原始数据中存在的问题：
  存在不一致（ 数据内含出现不一致情况）、重复、不完整(没有感兴趣的属性)、含噪声 （数据中存在着错误）、高维度或异常（偏离期望值）的数据。

### 数据预处理的方法××

（1）数据清洗 —— 去噪声和无关数据；
  （2）数据集成 —— 将多个数据源中的数据结合起来存放在一个一致的数据存储中；
  （3）数据变换 —— 把原始数据转换成为适合数据挖掘的形式；
  （4）数据规约 —— 主要方法包括：数据立方体聚集，维度归约，数据压缩，数值归约，离散化和概念分层等。

### 数据集成××

数据集成是指将不同应用系统、不同数据形式，在原应用系统不做任何改变的条件下，进行数据采集、转换和存储的数据整合过程。

### 数据集成面临的问题×××

异构性
异构性是异构数据集成必须面临的首要问题，其主要表现在两方面:
（1）系统异构
数据源所依赖的应用系统、数据库管理系统乃至操作系统之间的不同构成了系统异构。

（2）模式异构
数据源在存储模式上的不同。一般的存储模式包括关系模式、对象模式、对象关系模式和文档模式等几种，其中关系模式为主流存储模式。



完整性
(1)异构数据 
源数据集成的目的是为应用提供统一的访问支持。为了满足各种应用处理(包括发布)数据的条件，集成后的数据必须保证的完整性，包括数据完整性和数据集成的方法及技术。

（２）数据集成 
是指将不同应用系统、不同数据形式，在原应用系统不做任何改变的条件下，进行数据采集、转换和存储的数据整合过程。
面对以上几方面问题，产生了相关的数据变换技术和数据集成技术

### 异构数据交换方式

数据分布＼数据集成和交易自动化

## 大数据存储

### 处理海量数据存储中存在的问题×××

目前大数据存储面临几个问题：
一是存储数据的成本在不断地增加，如何削减开支节约成本以保证高可用性；
二是数据存储容量爆炸性增长且难以预估；
三是越来越复杂的环境使得存储的数据无法管理。企业信息架构如何适应现状去提供一个较为理想的解决方案，目前业界有几个发展方向。 

存储虚拟化　　容量拓展

### 海量数据存储技术×

虚拟存储技术　高性能Ｉ／Ｏ　　网格存储系统

### 海量数据存储的处理方法×××

(1)选用优秀的数据库工具 
(2)编写优良的程序代码 
(3)对海量数据进行分区操作 
(4)建立广泛的索引 
(5)建立缓存机制 
(6)加大虚拟内存
(7)分批处理 
(8)使用临时表和中间表 
(9)优化查询SQL语句

(10)使用文本格式进行处理 
(11)定制强大的清洗规则和出错处理机制 
(12)建立视图或者物化视图 
(13)避免使用32位机子（极端情况） 
(14)考虑操作系统问题 
(15)使用数据仓库和多维数据库存储 
(16)使用采样数据，进行数据挖掘 
(17)海量数据关联存储

### 云存储定义××

云存储是通过集群应用、网格技术或分布式文件系统等，将网络中大量各种不同的存储设备通过应用软件集合起来协同工作，共同对外提供数据存储和业务访问功能的一个系统。

### 云存储架构×××

云存储是由一个网络设备、存储设备、服务器、应用软件、公用访问接口、接入网和客户端程序等组成的复杂系统。
以存储设备为核心，通过应用软件来对外提供数据存储和业务访问服务。云存储的架构如下图所示：

![image-20220503133127567](C:\Users\A\AppData\Roaming\Typora\typora-user-images\image-20220503133127567.png)

存储层：
存储设备数量庞大且分布在不同地域，彼此通过广域网、互联网或光纤通道网络连接在一起。
在存储设备之上是一个统一存储设备管理系统， 实现存储设备的逻辑虚拟化管理、多链路冗余管理，以及硬件设备的状态监控和故障维护。

基础管理层：
通过集群、分布式文件系统和网格计算等技术，实现云存储设备之间的协同工作，使多个的存储设备可以对外提供同一种服务， 并提供更大更强更好的数据访问性能。
数据加密技术保证云存储中的数据不会被未授权的用户访问， 数据备份和容灾技术可以保证云存储中的数据不会丢失， 保证云存储自身的安全和稳定。

（3）应用接口层：
不同的云存储运营商根据业务类型，开发不同的服务接口，提供不同的服务。例如视频监控、视频点播应用平台、网络硬盘，远程数据备份应用等。
（4）访问层：
授权用户可以通过标准的公用应用接口来登录云存储系统，享受云存储服务。

### 数据库分类×

层次式数据库＼网络式数据库＼关系式数据库

### ＮｏＳＱＬ数据库四大分类×

键值存储数据库＼列存储数据库＼文档型数据库＼图形数据库

### 适用场景×××

NoSQL数据库在以下的这几种情况下比较适用：
1、数据模型比较简单；
2、需要灵活性更强的IT系统；
3、对数据库性能要求较高；
4、不需要高度的数据一致性；
5、对于给定key，比较容易映射复杂值的环境。

### 数据仓库概念××

主要功能是将透过资讯系统之联机事务处理(OLTP)经年累月所累积的大量资料，透过数据仓库理论所特有的资料储存架构，作一有系统的分析整理，以利各种分析方法如联机分析处理(OLAP)、数据挖掘(Data Mining)之进行，并进而支持如决策支持系统(DSS)、主管资讯系统(EIS)之创建，帮助决策者能快速有效的从大量资料中，分析出有价值的资讯，以利决策拟定及快速回应外在环境变动，帮助建构商业智能(BI)。

### 特点×××

效率足够高。
数据仓库的分析数据一般分为日、周、月、季、年等，可以看出，日为周期的数据要求的效率最高，要求24小时甚至12小时内，客户能看到昨天的数据分析。 

数据质量。
数据仓库所提供的各种信息，肯定要准确的数据，但由于数据仓库流程通常分为多个步骤，包括数据清洗，装载，查询，展现等等，复杂的架构会更多层次，那么由于数据源有脏数据或者代码不严谨，都可以导致数据失真，客户看到错误的信息就可能导致分析出错误的决策，造成损失，而不是效益。

扩展性。
之所以有的大型数据仓库系统架构设计复杂，是因为考虑到了未来3-5年的扩展性，这样的话，未来不用太快花钱去重建数据仓库系统，就能很稳定运行。主要体现在数据建模的合理性，数据仓库方案中多出一些中间层，使海量数据流有足够的缓冲，不至于数据量大很多，就运行不起来了。

面向主题
操作型数据库的数据组织面向事务处理任务，各个业务系统之间各自分离，而数据仓库中的数据是按照一定的主题域进行组织的。
主题是与传统数据库的面向应用相对应的，是一个抽象概念，是在较高层次上将企业信息系统中的数据综合、归类并进行分析利用的抽象。
每一个主题对应一个宏观的分析领域。数据仓库排除对于决策无用的数据，提供特定主题的简明视图

### 数据仓库系统的构成×××

一个典型的数据仓库系统主要有以下几部分构成：
A、数据仓库数据库：
是整个数据仓库环境的核心，是数据存放的地方和提供对数据检索的支持。
相对于操纵型数据库来说其突出的特点是对海量数据的支持和快速的检索技术。

数据抽取工具：
把数据从各种各样的存储方式中拿出来，进行必要的转化、整理，再存放到数据仓库内。
对各种不同数据存储方式的访问能力是数据抽取工具的关键，应能生成COBOL程序、MVS作业控制语言（JCL）、UNIX脚本、和SQL语句等，以访问不同的数据。 

元数据：
元数据是描述数据仓库内数据的结构和建立方法的数据。可将其按用途的不同分为两类，技术元数据和商业元数据。
技术元数据是数据仓库的设计和管理人员用于开发和日常管理数据仓库使用的数据。
包括：数据源信息；数据转换的描述；数据仓库内对象和数据结构的定义；数据清理和数据更新时用的规则；源数据到目的数据的映射；用户访问权限；数据备份历史记录、数据导入历史记录、信息发布历史记录等。

D、访问工具：
为用户访问数据仓库提供手段。有数据查询和报表工具、应用开发工具、管理信息系统工具、在线分析（OLAP）工具和数据挖掘（DM）工具等。
E、数据集市（Data Marts）：
为了特定的应用目的或应用范围而从数据仓库中独立出来的一部分数据，也可称为部门数据或主题数据（subject area）。在数据仓库的实施过程中往往可以从一个部门的数据集市着手，以后再用几个数据集市组成一个完整的数据仓库。

F、数据仓库管理：
包括安全和特权管理、跟踪数据的更新、数据质量检查、管理和更新元数据、审计和报告数据仓库的使用和状态、删除数据、复制、分割和分发数据、备份和恢复以及存储管理。
G、信息发布系统：
把数据仓库中的数据或其它相关的数据发送给不同的地点或用户。基于Web的信息发布系统是对付多用户访问的最有效方法。

### 元数据管理××

元数据（Meta Date），其实应该叫做解释性数据，即数据的数据。主要记录数据仓库中模型的定义、各层级间的映射关系、监控数据仓库的数据状态及ETL的任务运行状态。
一般会通过元数据资料库（Metadata Repository）来统一地存储和管理元数据，其主要目的是使数据仓库的设计、部署、操作和管理能达成协同和一致。

## 大数据计算

### 大数据计算模式××

根据大数据的不同数据特征和计算特征，从多样性的大数据计算问题和需求中提炼并建立的各种高层抽象（Abstraction）或模型（Model）。

### 大数据计算分类×

离线批处理计算＼实时交互计算＼流计算

### 实时交互计算×××

最重要的需求：能够事实相应计算结果，一般要求微秒级。

实时计算一般可以分为以下两种应用场景：

数据量巨大且不能提前计算出结果的,但要求对用户的响应时间是实时的。
主要用于特定场合下的数据分析处理.当数据量庞大,同时发现无法穷举所有可能条件的查询组合,或者大量穷举出来的条件组合无用的时候,实时计算就可以发挥作用,将计算过程推迟到查询阶段进行,但需要为用户提供实时响应.

数据源是实时的不间断的,要求对用户的响应时间也是实时的。
数据源实时不间断的也称为流式数据.所谓流式数据是指将数据看作是数据流的形式来处理.
数据流是在时间分布和数量上无限的一系列数据记录的集合体;数据记录是数据流的最小组成单元.
例如,在物联网领域传感器产生的数据可能是源源不断的.
实时的数据计算和分析可以动态实时地对数据进行分析统计,对于系统的状态监控、调度管理具有重要的实际意义。

## 实时查询服务××

实时查询服务的实现可以分为三种方式:
1) 全内存:直接提供数据读取服务,定期dump到磁盘或数据库进行持久化。
2) 半内存:使用Redis、Memcache、MongoDB、BerkeleyDB等数据库提供数据实时查询服务,由这些系统进行持久化操作。
3) 全磁盘:使用HBase等以分布式文件系统(HDFS)为基础的NoSQL数据库,对于key-value引擎,关键是设计好key的分布。

### 数据分类与聚类×

划分聚类＼层次聚类＼基于密度的聚类＼基于表格的聚类

### 传统数据集成方法的不足×××

传统数据集成方法存在不足之处。它们不能解决当今 IT 环境的复杂性，也不能覆盖 IT 必须执行的一系列方案的处理。 
	对于连接数百（或数千）个应用程序的不同单点解决方案，它们仅仅分裂运营数据并将其锁定在部门应用程序中，例如 ERP 和 CRM。

以应用程序为中心的数据集成方法没有考虑所有企业数据。
例如，它们不能处理计划数据，这些计划数据通常保存在 Excel 电子数据表中，而未保存在部门数据库应用程序中。
它们也不能解决驻留在企业外部的有关供应商的数据或与贸易合作伙伴共享的数据。

手动编码数据集成方法也不起作用。手动编码费时费力，并且还容易犯错。由于 IT 机构力求管理更多的数据和更多的数据格式，手动编码通常导致更复杂 － 而不是更简单

### 新的数据集成方法的特点×××

IT 机构需要采用可靠的新方法进行数据集成 － 新方法可以：
集成企业内的所有内部预置数据孤岛，包括非结构化数据
集成云计算应用程序和系统中的外部数据
与贸易合作伙伴之间以企业对企业的形式无缝交换数据
确保所有数据的质量 
经济高效地管理应用程序生命周期 

数据集成平台是一整套全面的技术，包括访问、发现、清洗、集成并为扩张的企业提供数据。
数据集成平台支持各种数据集成项目，例如：数据仓库、数据迁移、测试数据管理、数据存档、数据整合、主数据管理、数据同步、B2B Data Exchange

## 大数据查询　显现与交互

### 常规数据查询结构化数据××

ｓｑｌ语言是一种特殊目的的编程语言，是一种数据库查询和程序设计语言，用于存取数据以及查询＼更新和管理数据库系统，同时也是数据库脚本文件的拓展名。

## 结构化查询语言包含六个部分×

数据查询语言ＤＱＬ

数据操作语言ＤＭＬ

事务处理语言ＴＰＬ

数据控制语言ＤＣＬ

数据定义语言ＤＤｌ

指针控制语言ＣＣＬ

### 搜索引擎分类

全文索引　　

目录索引

元搜索引擎

### 搜索引擎的体系结构设计×××

信息采集
Web搜索引擎的信息采集模块的主要功能是：
执行基于超文本传输协议（Hypertext Transfer Protocol, 简称HTTP），从Web上收集页面信息，即Web机器人（爬虫）程序。

索引技术
① 网络爬虫程序的工作模式
网络爬虫程序根据HTTP协议，发送请求，并通过TCP连接接受服务器的应答。
由于Web搜索引擎需要抓取数以亿计的页面，所以建立快速分布式的网络爬虫程序才能满足搜索引擎对性能和服务的要求，其物理实现可能是一组终端。

网络爬虫程序的基础结构
首先网络爬虫程序从URL链接库读取一个或多个URL作为初始输入并进行域名解析
然后根据域名解析结果（IP）访问Web服务器，建立TCP连接，发送请求，接受应答，储存接受数据，并分析提取链接信息（URL）放入URL连接库里。
爬虫程序递归执行该过程直到URL链接库为空。网络爬虫程序的基础结构如下图：

信息采集优化
LRU（Least Recently Used）算法：将最近最少使用的内容替换出Cache缓存；
LFU（Lease Frequently Used）算法：将访问次数最少的内容替换出Cache缓存；
FIFO（First-In, First-Out）算法：在Cache缓存中执行数据的先进先出流程方法。

网页抓取算法
①深度优先算法
在Web收集页面信息时，使用一个或一组预定义URL地址开始，然后根据页面内容中的超链接深度抓取页面，直到搜索结束（没有新的URL）。
②广度优先算法
在Web收集页面信息时，使用一个或一组预定义URL地址开始，然后根据页面内容中的超链接广度抓取页面，抓取下一层的URL直到这一层的URL完全被抓取，直到搜索结束时返回。

基于内容算法
根据关键字、主题文档的相似度和链接文本（Linked texts）估计链接值，并确定相应搜索策略的算法。
链接文本是包含对URL链接解释说明和内容摘要的文字信息。
④基于HITS的算法
主要思想：在抓取Web页面时，采用Authority/Hub抓取策略。Authority表示该页面被其他页面所引用的次数（页面入度值，in-degree value）。Hub表示其他页面引用该页面的次数（页面出度值，out-degree value）。

PageRank（Google的专利技术）
Google的PageRank根据网站的外部链接和内部链接的数量和质量来衡量网站的价值。PageRank背后的概念是，每个到页面的链接都是对该页面的一次投票，被链接的越多，就意味着被其他网站投票越多。
这个就是所谓的“链接流行度”——衡量多少人愿意将他们的网站和你的网站挂钩。PageRank这个概念引自学术中一篇论文的被引述的频度——即被别人引述的次数越多，一般判断这篇论文的权威性就越高。 

索引技术
  Web爬虫抓取回来的页面信息，需要放入索引数据库里。文本分析技术是建立数据索引信息的支撑技术。
索引建立：预处理
索引建立：倒排文件模型
倒排文件（inverted file），是指一个词汇集合W和一个文档集合D之间对应关系的数据结构。建立倒排文件索引是建立索引数据库的核心工作。 

搜索服务
①结果显示
接受用户的输入，提交用户搜索请求。
②网页快照
Web搜索引擎为了提高服务质量，需要对搜索到的页面信息进行快照，以便在原来页面信息失效的情况下，保证用户能够通过快照功能查看页面。

### 哈希方法和区间方法

随机方法将所有数据随机分布到不同的节点，这种方法不支持更新操作。
哈希方法根据某个列或者某些列（称为分布键）的哈希值将数据分布到不同的节点。
区间方法将所有的数据按照不同区间分布到不同的节点。区间到节点的映射信息需要保存下来。

### 相似性搜索工具可能的应用

可以用相似性搜索工具找出和当前城市在人口、教育以及临近特定娱乐机会方面相似的其他城市。
当地领导干部可能希望促进其城市的潜在业务，从而提高税收。
人力资源经理可能希望能够证明公司的工资范围。找出在大小、生活成本、市容建筑方面相似的城市后，她便可以查看这些城市的工资范围，从而查看他们是否在此行列

犯罪分析师希望搜索数据库以查看某罪行是否属于较重犯罪形式或有重罪趋势。执法机构用此方法揭露毒品种植地或生产地。标识具有相似特征的地方可能有助于制定未来的搜索目标。
大型零售商不仅拥有数个成功店铺，也有少数业绩不佳的店铺。找到一些具有相似人口特征和环境特征（交通便利性、知名度以及商业互补性等等）的地方有助于标识新店的最佳位置

### 数据可视化定义××

数据可视化为人们提供了从阅读局部信息到纵观全局信息、从表面到本质和从内容到结构的有力工具。其演化过程是从文本到树和图, 再到多媒体, 以便最大限度地利用人们的多通道和分布式认知功能以及形象思维功能, 达到意会。

### 知识图谱的概念××

知识图谱(Knowledge Graph)本质上是语义网络，是一种基于图的数据结构，由节点(Point)和边(Edge)组成。在知识图谱里，每个节点表示现实世界中存在的“实体”，每条边为实体与实体之间的“关系”。知识图谱是关系的最有效的表示方式。

### 知识图谱的挑战×××

1）数据的噪声
首先，数据中存在着很多的噪声。即便是已经存在库里的数据，我们也不能保证它有100%的准确性。在这里主要从两个方面说起。
第一，目前积累的数据本身有错误，所以这部分错误数据需要纠正。 最简单的纠正办法就是做离线的不一致性验证，这点在前面提过。

非结构化数据处理能力
在大数据时代，很多数据都是未经处理过的非结构化数据，比如文本、图片、音频、视频等。特别在互联网金融行业里，我们往往会面对大量的文本数据。
怎么从这些非结构化数据里提取出有价值的信息是一件非常有挑战性的任务，这对掌握的机器学习，数据挖掘，自然语言处理能力提出了更高的门槛。

知识推理
推理能力是人类智能的重要特征，使得我们可以从已有的知识中发现隐含的知识， 一般的推理往往需要一些规则的支持。
例如“朋友”的“朋友”，可以推理出“朋友”关系，“父亲”的“父亲”可以推理出“祖父”的关系。再比如张三的朋友很多也是李四的朋友，那我们可以推测张三和李四也很有可能是朋友关系。